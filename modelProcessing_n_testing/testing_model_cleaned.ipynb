{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:38.250772Z",
     "start_time": "2019-04-24T10:44:36.711033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# # automatically reload modules when they have changed\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import keras\n",
    "import  keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.config import read_config_file\n",
    "import IPython.display as Disp\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2,datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import time,itertools\n",
    "import pandas as pd\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:38.255689Z",
     "start_time": "2019-04-24T10:44:38.253435Z"
    }
   },
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RetinaNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:38.353183Z",
     "start_time": "2019-04-24T10:44:38.258109Z"
    }
   },
   "outputs": [],
   "source": [
    "# from keras_retinanet.models.retinanet import retinanet_bbox,AnchorParameters\n",
    "\n",
    "# from keras_retinanet.models.resnet import ResNetBackbone as b\n",
    "\n",
    "# def backbone(backbone_name):\n",
    "#     \"\"\" Returns a backbone object for the given backbone.\n",
    "#     \"\"\"\n",
    "#     if 'resnet' in backbone_name:\n",
    "#         from .resnet import ResNetBackbone as b\n",
    "#     elif 'mobilenet' in backbone_name:\n",
    "#         from .mobilenet import MobileNetBackbone as b\n",
    "#     elif 'vgg' in backbone_name:\n",
    "#         from .vgg import VGGBackbone as b\n",
    "#     elif 'densenet' in backbone_name:\n",
    "#         from .densenet import DenseNetBackbone as b\n",
    "#     else:\n",
    "#         raise NotImplementedError('Backbone class for  \\'{}\\' not implemented.'.format(backbone))\n",
    "\n",
    "#     return b(backbone_name)\n",
    "\n",
    "# def load_model(filepath, backbone_name='resnet50', convert=False, nms=True,anchor_parameters = None):\n",
    "#     \"\"\" Loads a retinanet model using the correct custom objects.\n",
    "\n",
    "#     # Arguments\n",
    "#         filepath: one of the following:\n",
    "#             - string, path to the saved model, or\n",
    "#             - h5py.File object from which to load the model\n",
    "#         backbone_name: Backbone with which the model was trained.\n",
    "#         convert: Boolean, whether to convert the model to an inference model.\n",
    "#         nms: Boolean, whether to add NMS filtering to the converted model. Only valid if convert=True.\n",
    "#         anchor_parameters: AnchorParameters object pass to predict model, if omitted the AnchorParameters.default is assumed. This argument is valid only when 'convert' is set to True.\n",
    "\n",
    "#     # Returns\n",
    "#         A keras.models.Model object.\n",
    "\n",
    "#     # Raises\n",
    "#         ImportError: if h5py is not available.\n",
    "#         ValueError: In case of an invalid savefile.\n",
    "#     \"\"\"\n",
    "\n",
    "#     model = keras.models.load_model(filepath, custom_objects=b(backbone_name).custom_objects)\n",
    "#     if convert:\n",
    "#         anchor_parameters = anchor_parameters if anchor_parameters is not None else AnchorParameters.default\n",
    "#         model = retinanet_bbox(model=model, nms=nms,anchor_parameters = anchor_parameters,num_anchors=9)\n",
    "\n",
    "#     return model\n",
    "\n",
    "# anchor_params = read_config_file('inference_model_4/config.ini')\n",
    "\n",
    "# model = load_model('inference_model_4/resnet50_csv_01.h5',convert=True,anchor_parameters=anchor_params)\n",
    "\n",
    "# from keras_retinanet.utils.anchors import AnchorParameters\n",
    "\n",
    "# AnchorParameters.default.sizes   = [16, 32, 64, 128, 256, 512]\n",
    "# AnchorParameters.default.strides = [8, 16, 32, 64, 128]\n",
    "\n",
    "# model.predict_on_batch(np.array(np.expand_dims(image,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:42.880873Z",
     "start_time": "2019-04-24T10:44:38.356085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/prateek/.virtualenvs/cv_p35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prateek/.virtualenvs/cv_p35/lib/python3.5/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# adjust this to point to your downloaded/trained model\n",
    "# models can be downloaded here: https//github.com/fizyr/keras-retinanet/releases\n",
    "model_path = 'inference_model_with_worker/resnet50_csv_06_inference.h5'# load reinference_model/net model\n",
    "\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n",
    "\n",
    "# if the model is not converted to an inference model, use the line below\n",
    "# see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model\n",
    "#model = models.load_model(model_path, backbone_name='resnet50', convert=True)\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "# load label to names mapping for visualization purposes\n",
    "labels_map= pd.read_csv('inference_model_with_worker/class_mapping.csv',header=None)\n",
    "\n",
    "#labels_to_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
    "labels_to_names = dict(zip(labels_map[1],labels_map[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:42.899486Z",
     "start_time": "2019-04-24T10:44:42.883084Z"
    }
   },
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # box x1,y1,x2,y2\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA ) * max(0, yB - yA )\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    io_minArea = interArea/(float(min(boxAArea,boxBArea)))\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou,io_minArea\n",
    "\n",
    "def bb_intersection_over_union_li(boxes_li):\n",
    "\n",
    "    return bb_intersection_over_union(boxes_li[0],boxes_li[1])\n",
    "comb_pair = lambda a,b : [(x,y) for x in a for y in b]\n",
    "\n",
    "\n",
    "# def test_flitering(boxes, scores, labels, iou_threshold=.80, labels_pairs=[[1,2],[3,4]], threshold=.51):\n",
    "#     # combs = list(itertools.combinations(df.index,2))\n",
    "#     # filt_combs = [i[0] for i in list(zip(combs,[bb_intersection_over_union(df.loc[comb[0]]['boxes'],df.loc[comb[1]]['boxes']) for comb in combs])) if i[1]>0]\n",
    "#     df = pd.DataFrame({'boxes':boxes.tolist(), 'scores':scores, 'labels':labels})\n",
    "#     df = df[df.scores>=threshold]\n",
    "    \n",
    "#     for pair_i in labels_pairs:\n",
    "#         df_1 = df[df.labels.isin(pair_i)]\n",
    "        \n",
    "#         index_a = df_1[df_1.labels==pair_i[0]].index\n",
    "#         index_b = df_1[df_1.labels==pair_i[1]].index\n",
    "#         iou_arr = np.zeros([max(index_a, default=0)+1, max(index_b,default=0)+1])\n",
    "#         combs = comb_pair(index_a, index_b)\n",
    "#         for comb in combs:\n",
    "#             iou_arr[comb] = bb_intersection_over_union(df_1.loc[comb[0]].boxes,df_1.loc[comb[1]].boxes)\n",
    "#         filtered_iou = np.where(iou_arr>iou_threshold)  \n",
    "#         filtered_iou = [x for x in filtered_iou if x.size!=0]\n",
    "#         drop_idx = [df_1.loc[comb].sort_values(['scores']).index[0] for comb in filtered_iou]\n",
    "#         df.drop(drop_idx,inplace=True)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "def filter_multiple_detections_anuj(boxes, scores, labels, iou_threshold=.80, labels_pairs=[[1,2],[3,4], [1, 1]], threshold=0.5):\n",
    "    df = pd.DataFrame({'boxes':boxes.tolist(), 'scores':scores, 'labels':labels})\n",
    "    df = df[df.scores>=threshold]\n",
    "    \n",
    "    for pair_i in labels_pairs:\n",
    "        df_1 = df[df.labels.isin(pair_i)]\n",
    "        \n",
    "        index_a = df_1[df_1.labels==pair_i[0]].index\n",
    "        index_b = df_1[df_1.labels==pair_i[1]].index\n",
    "        iou_arr = np.zeros([max(index_a, default=0)+1, max(index_b,default=0)+1])\n",
    "        combs = comb_pair(index_a, index_b)\n",
    "        \n",
    "        for comb in combs:\n",
    "            iou_value = bb_intersection_over_union(df_1.loc[comb[0]].boxes,df_1.loc[comb[1]].boxes)\n",
    "            if iou_value != 1:\n",
    "                iou_arr[comb] = iou_value\n",
    "        filtered_iou = np.where((iou_arr>iou_threshold))\n",
    "        filtered_iou = [x for x in filtered_iou if x.size!=0]\n",
    "        drop_idx = [df_1.loc[comb].sort_values(['scores']).index[0] for comb in filtered_iou]\n",
    "        df.drop(drop_idx,inplace=True)\n",
    "    return df\n",
    "\n",
    "def filter_multiple_detections(boxes, scores, labels, iou_threshold=.80, labels_pairs=[[1,2],[3,4], [0, 0]], threshold=0.5):\n",
    "    df = pd.DataFrame({'boxes':boxes.tolist(), 'scores':scores, 'labels':labels})\n",
    "    df = df[df.labels!=-1]\n",
    "    df = df[df.scores>=threshold]\n",
    "    \n",
    "    \n",
    "    for pair_i in labels_pairs:\n",
    "        df_1 = df[df.labels.isin(pair_i)]\n",
    "        combs = list(itertools.combinations(df_1.index,2))\n",
    "        ### minm area utility is used\n",
    "        min_iou = [bb_intersection_over_union_li(df_1.loc[list(comb)]['boxes'].tolist())[1] for comb in combs]\n",
    "        ## combination that are repeated\n",
    "        rep_combs = [combs[idx] for idx,ious in enumerate(min_iou) if ious>=iou_threshold]\n",
    "        ### index of those combinations\n",
    "        rep_idx = [df.loc[list(comb)]['scores'].idxmin() for comb in rep_combs]\n",
    "        ### droping those index\n",
    "        df.drop(rep_idx,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:43.066684Z",
     "start_time": "2019-04-24T10:44:42.900950Z"
    }
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# comb_pair([1,2,3],[4,5,6])+list(itertools.combinations([1,2,3])+list)\n",
    "\n",
    "# %%pixie_debugger\n",
    "# for pair_i in labels_pairs:\n",
    "#     df_1 = df[df.labels.isin(pair_i)]\n",
    "\n",
    "#     index_a = df_1[df_1.labels==pair_i[0]].index\n",
    "#     index_b = df_1[df_1.labels==pair_i[1]].index\n",
    "#     iou_arr = np.zeros([max(index_a, default=0)+1, max(index_b,default=0)+1])\n",
    "#     combs = comb_pair(index_a, index_b)\n",
    "\n",
    "#     for comb in combs:\n",
    "#         iou_value = bb_intersection_over_union(df_1.loc[comb[0]].boxes,df_1.loc[comb[1]].boxes)\n",
    "#         if iou_value != 1:\n",
    "#             iou_arr[comb] = iou_value\n",
    "#     filtered_iou = np.where((iou_arr>iou_threshold))\n",
    "#     filtered_iou = [x for x in filtered_iou if x.size!=0]\n",
    "#     drop_idx = [df_1.loc[comb].sort_values(['scores']).index[0] for comb in filtered_iou]\n",
    "#     df.drop(drop_idx,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:43.220497Z",
     "start_time": "2019-04-24T10:44:43.068049Z"
    }
   },
   "outputs": [],
   "source": [
    "#bb_intersection_over_union([0,0,100,100],[50,50,150,150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:43.321721Z",
     "start_time": "2019-04-24T10:44:43.221912Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_img(channels,caps,bordersize=0,border_color=[0,0,0]):\n",
    "    if len(channels)==1:\n",
    "        if caps is None:\n",
    "            caps = [cv2.VideoCapture(channel) for channel in channels]\n",
    "        ret_image = [cap.read() for cap in caps]\n",
    "        image,ret = ret_image[0][1],ret_image[0][0]\n",
    "    if len(channels)>1:\n",
    "        if caps is None:\n",
    "            caps = [cv2.VideoCapture(channel) for channel in channels]\n",
    "        ret_frame = [cap.read() for cap in caps]\n",
    "        frames = [i[1] for i in ret_frame if i[0]]\n",
    "        ret = all([i[0] for i in ret_frame])\n",
    "        image_v = []\n",
    "        if len(frames)%2!=0:\n",
    "            frames.append(np.zeros_like(frames[-1]))\n",
    "        for i in range(0,len(frames),2):\n",
    "            image1=cv2.copyMakeBorder(frames[i], top=0, bottom=0, \n",
    "                      left=0, right=bordersize, borderType= cv2.BORDER_CONSTANT, value=border_color )\n",
    "            image2= frames[i+1]\n",
    "            image_v_1 = np.concatenate([image1,image2],axis=1)\n",
    "            if i!=len(frames)-2:\n",
    "                image_v_1 = cv2.copyMakeBorder(image_v_1, top=0, bottom=bordersize, \n",
    "                              left=0, right=0, borderType= cv2.BORDER_CONSTANT, value=border_color ) \n",
    "            image_v.append(image_v_1)\n",
    "        image = np.concatenate(image_v,axis=0) \n",
    "    return image,caps,ret\n",
    "\n",
    "def cap_release(caps):\n",
    "    [cap.release() for cap in caps]\n",
    "    \n",
    "def check_if_blue(img,thresh=.5):\n",
    "    #rgb\n",
    "    r,g,b = img[:,:,0],img[:,:,1],img[:,:,2]\n",
    "    if (np.logical_and((b>g),(b>r)).sum()/(img.shape[0]*img.shape[1]))>thresh :\n",
    "        return True\n",
    "    else:\n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:43.446630Z",
     "start_time": "2019-04-24T10:44:43.323121Z"
    }
   },
   "outputs": [],
   "source": [
    "def li2dict(li):\n",
    "    return {'x1':li[0],'y1':li[1],'x2':li[2],'y2':li[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:44:43.564966Z",
     "start_time": "2019-04-24T10:44:43.447930Z"
    }
   },
   "outputs": [],
   "source": [
    "def cnvt2dict(df):\n",
    "    dict_main = {}\n",
    "    helmet = []\n",
    "    vest = []\n",
    "    person = []\n",
    "    for row in df.iterrows():    \n",
    "        dict_helmet = {}\n",
    "        dict_vest = {}\n",
    "        dict_person = {}\n",
    "        label = row[1]['labels']\n",
    "        box1 = np.array(row[1]['boxes'], dtype= str)\n",
    "        score1 = str(row[1]['scores'])\n",
    "\n",
    "        if label=='helmet':\n",
    "            dict_helmet['violation'] = False\n",
    "            dict_helmet['score'] = score1\n",
    "            dict_helmet['bbox'] = li2dict(box1)\n",
    "        if label=='vest':\n",
    "            dict_vest['violation'] = False\n",
    "            dict_vest['score'] = score1\n",
    "            dict_vest['bbox'] = li2dict(box1)\n",
    "        if label=='no_helmet':\n",
    "            dict_helmet['violation'] = True\n",
    "            dict_helmet['score'] = score1\n",
    "            dict_helmet['bbox'] = li2dict(box1)\n",
    "        if label=='no_vest':\n",
    "            dict_vest['violation'] = True\n",
    "            dict_vest['score'] = score1\n",
    "            dict_vest['bbox'] = li2dict(box1)    \n",
    "        if label=='person':\n",
    "            dict_person['score'] = score1\n",
    "            dict_person['bbox'] = li2dict(box1)\n",
    "        if bool(dict_vest):\n",
    "            vest.append(dict_vest)\n",
    "        if bool(dict_helmet):\n",
    "            helmet.append(dict_helmet)\n",
    "        if bool(dict_person):\n",
    "            person.append(dict_person)\n",
    "    dict_main['helmet'] = helmet\n",
    "    dict_main['vest'] = vest\n",
    "    dict_main['person'] = person\n",
    "    return dict_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-24T10:50:19.917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS:  8.438581278330272\n"
     ]
    }
   ],
   "source": [
    "# load image\n",
    "#image = read_image_bgr('000000008021.jpg')\n",
    "bbox_colors = [(0,0,0),(0,255,0),(255,0,0),(0,255,0),(255,0,0),(0,0,255)]\n",
    "thresh_score = .6\n",
    "plot_blue = True\n",
    "preprocess_flag = True\n",
    "caps = None\n",
    "urls = ['rtsp://admin:admin@123@10.10.12.21:554/Streaming/Channels/101/',\n",
    "        'rtsp://admin:admin@123@10.10.12.21:554/Streaming/Channels/201/',\n",
    "        'rtsp://admin:admin@123@10.10.12.21:554/Streaming/Channels/301/',\n",
    "       'rtsp://admin:admin@123@10.10.12.21:554/Streaming/Channels/401/']\n",
    "urls = ['/home/prateek/Desktop/Video_Data/Video/9.Stacker_bay_devi_stack_counter/Camera8_project office_project office_20181219103622_20181219103632_16005375.mp4']\n",
    "#urls = ['/media/prateek/D41D-3DB3/Drone new 26-02-2019/DJI_0165.MOV']\n",
    "#urls = ['rtsp://admin:admin@123@10.10.12.21:554:554/Streaming/Channels/401/']\n",
    "#hotmil_view: rtsp://user:operator@123@10.36.12.122:554:554/Streaming/Channels/601/\n",
    "urls = ['rtsp://user:operator@123@10.36.12.122:554/Streaming/Channels/1601/']\n",
    "urls = ['rtsp://user:operator@123@10.36.12.122:554/Streaming/Channels/601/']\n",
    "urls = ['/home/prateek/Desktop/Video_Data/low_light_data/Hot_Mill_View_Low_Light.mp4']\n",
    "#urls = ['/home/prateek/Desktop/Video_Data/new_data_11_01/hot_mill_view/file_0003.mp4']\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "def nothing(x):\n",
    "    pass\n",
    "write_video = True\n",
    "\n",
    "cv2.namedWindow('preview',cv2.WINDOW_NORMAL)\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('detection_threshold','preview',50,100,nothing)\n",
    "cv2.createTrackbar('iou_threshold','preview',50,100,nothing)\n",
    "\n",
    "\n",
    "#cap.set(1,100v0)\n",
    "\n",
    "bordersize=0\n",
    "border_color = [0,0,0]\n",
    "r = None\n",
    "\n",
    "all_preds = []\n",
    "while True:\n",
    "    Disp.clear_output(wait=True)\n",
    "    for i in range(1):\n",
    "        #################################multi feed functionality#############################################\n",
    "        image,caps,ret = read_img(urls,caps,bordersize=bordersize)\n",
    "        ######################################################################################################\n",
    "    \n",
    "\n",
    "\n",
    "    #image = cv2.rotate(image,1)\n",
    "    if not ret:\n",
    "        break\n",
    "        # Select ROI\n",
    "    if r is None:\n",
    "        r = cv2.selectROI(\"select_ROI\",image)    \n",
    "        if r[2]*r[3]<10:\n",
    "            r = [0,0,image.shape[1],image.shape[0]]\n",
    "        cv2.destroyWindow(\"select_ROI\")\n",
    "    # Crop image\n",
    "    image = image[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    if write_video:\n",
    "        try:\n",
    "            out = cv2.VideoWriter('../output/out_'+datetime.datetime.now().strftime(\"%I_%M_%p_%B_%d_%Y\")+'.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (draw.shape[1],draw.shape[0]))\n",
    "            write_video=False\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    if preprocess_flag:\n",
    "        # preprocess image for network\n",
    "        image = preprocess_image(image)\n",
    "        image, scale = resize_image(image)\n",
    "    #print(image.shape)\n",
    "    # process image\n",
    "    start = time.time()\n",
    "    #boxes, scores, labels = model.predict_on_batch(np.array([image,image]))\n",
    "    boxes, scores, labels = model.predict_on_batch(np.array(np.expand_dims(image,axis=0)))\n",
    "    #boxes,scores,labels = boxes[0],scores[0],labels[0]\n",
    "    print(\"FPS: \", 1/(time.time() - start))\n",
    "\n",
    "    if preprocess_flag:\n",
    "    # correct for image scale\n",
    "        boxes /= scale\n",
    "    detection_thresh_score = cv2.getTrackbarPos('detection_threshold','preview')\n",
    "    iou_thresh_score = cv2.getTrackbarPos('iou_threshold','preview')\n",
    "\n",
    "    #df = test_flitering(boxes[0], scores[0], labels[0],threshold=.01*thresh_score)\n",
    "    df = filter_multiple_detections(boxes[0], scores[0], labels[0],threshold=.01*detection_thresh_score,iou_threshold=.01*iou_thresh_score)\n",
    "    \n",
    "    preds = []\n",
    "    for row in  df.iterrows():\n",
    "        b = np.array(row[1]['boxes'],dtype='uint16')#\n",
    "        label = row[1]['labels']\n",
    "        score = row[1]['scores']\n",
    "        color = bbox_colors[(label)]\n",
    "        \n",
    "            \n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        draw_box(draw, b, color=color)\n",
    "        if plot_blue:\n",
    "            if label==4:\n",
    "                if check_if_blue(draw[b[1]:b[3],b[0]:b[2],:],.4):\n",
    "                    #caption = caption + '-- BLUE'\n",
    "                    caption = caption+' (worker)'\n",
    "                    draw_box(draw, b, color=[0,0,255])\n",
    "        \n",
    "        draw_caption(draw, b, caption)\n",
    "        preds.append(labels_to_names[label])\n",
    "        \n",
    "    \n",
    "\n",
    "    cv2.putText(draw,\"detection threshold = \"+str(.01*detection_thresh_score),(draw.shape[1]-500,40), font, 1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(draw,\"iou threshold = \"+str(.01*iou_thresh_score),(draw.shape[1]-500,80), font, 1,(0,0,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    draw_bgr = cv2.cvtColor(draw,cv2.COLOR_RGB2BGR)\n",
    "    out.write(draw_bgr)\n",
    "    \n",
    "    cv2.imshow(\"preview\",draw_bgr)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k==27:\n",
    "        cap_release(caps)\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    all_preds.append(preds)\n",
    "#out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cap_release(caps)#cap2.release()\n",
    "\n",
    "out.release()\n",
    "\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(draw)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0f42320da4a2a31d8e4f008823b1ba63"
  },
  "gist": {
   "data": {
    "description": "abg/helmet_n_vest/retinanet/testing_model_cleaned.ipynb",
    "public": false
   },
   "id": "0f42320da4a2a31d8e4f008823b1ba63"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "cv_p35",
   "language": "python",
   "name": "cv_p35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
