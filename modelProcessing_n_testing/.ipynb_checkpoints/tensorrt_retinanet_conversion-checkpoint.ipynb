{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:19:26.947719Z",
     "start_time": "2019-04-24T10:19:25.436345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Converts `SavedModel` to TensorRT graph and measures inference time.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "#import tensorrt as trt\n",
    "from tensorflow.python.saved_model import loader\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "import IPython.display as Disp\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:19:30.801705Z",
     "start_time": "2019-04-24T10:19:30.798134Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "image_url = 'https://tensorflow.org/images/blogs/serving/cat.jpg'\n",
    "saved_model_dir = '../inference_model_with_worker/resnet50_csv_06.pb'\n",
    "model_input = 'input_1:0'\n",
    "model_output = ['filtered_detections/map/TensorArrayStack/TensorArrayGatherV3:0',\n",
    "               'filtered_detections/map/TensorArrayStack_1/TensorArrayGatherV3:0',\n",
    "               'filtered_detections/map/TensorArrayStack_2/TensorArrayGatherV3:0']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading original tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:19:31.932712Z",
     "start_time": "2019-04-24T10:19:31.930326Z"
    }
   },
   "outputs": [],
   "source": [
    "# detection_graph = tf.Graph()\n",
    "# with detection_graph.as_default():\n",
    "#     od_graph_def = tf.GraphDef()\n",
    "#     with tf.gfile.GFile('tensorrt_model_testing/saved_model.pb', 'rb') as fid:\n",
    "#         serialized_graph = fid.read()\n",
    "#         od_graph_def.ParseFromString(serialized_graph)\n",
    "#         tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:19:32.735907Z",
     "start_time": "2019-04-24T10:19:32.732987Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_graph(frozen_model_file):\n",
    "    \"\"\"\n",
    "    returns graphdef(unserialized) object\n",
    "    \"\"\"\n",
    "    with tf.gfile.GFile(frozen_model_file,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:19:33.400302Z",
     "start_time": "2019-04-24T10:19:33.392734Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_graph(frozen_model_file,model_input=model_input,model_output=model_output):\n",
    "    \"\"\"\n",
    "    return loaded graph\n",
    "    \"\"\"\n",
    "    graph_def = get_graph(frozen_model_file)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### converting to tensorrt graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:19:44.574080Z",
     "start_time": "2019-04-24T10:19:35.258290Z"
    }
   },
   "outputs": [],
   "source": [
    "precision = \"FP32\"\n",
    "batch_size=2\n",
    "workspace_size=1 << 25\n",
    "trt_graph = trt.create_inference_graph(get_graph(saved_model_dir),model_output,\\\n",
    "                                       precision_mode=precision,max_workspace_size_bytes=workspace_size,\\\n",
    "                                      max_batch_size=batch_size,is_dynamic_op=True)\n",
    "\n",
    "with tf.gfile.GFile(saved_model_dir.replace('.pb','_precision='+precision+'_batchsize='+str(batch_size)+'_trt.pb'),'wb') as f:\n",
    "    f.write(trt_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T10:19:49.304359Z",
     "start_time": "2019-04-24T10:19:49.192912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numb. of all_nodes in frozen graph: 2011\n",
      "numb. of trt_engine_nodes in TensorRT graph: 7\n",
      "numb. of all_nodes in TensorRT graph: 1034\n"
     ]
    }
   ],
   "source": [
    "# check how many ops of the original frozen model\n",
    "all_nodes = len([1 for n in get_graph(saved_model_dir).node])\n",
    "print(\"numb. of all_nodes in frozen graph:\", all_nodes)\n",
    "\n",
    "# check how many ops that is converted to TensorRT engine\n",
    "trt_engine_nodes = len([1 for n in trt_graph.node if str(n.op) == 'TRTEngineOp'])\n",
    "print(\"numb. of trt_engine_nodes in TensorRT graph:\", trt_engine_nodes)\n",
    "all_nodes = len([1 for n in trt_graph.node])\n",
    "print(\"numb. of all_nodes in TensorRT graph:\", all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T10:40:37.372721Z",
     "start_time": "2019-04-15T10:40:37.306774Z"
    }
   },
   "outputs": [],
   "source": [
    "for n in trt_graph.node:\n",
    "    print(n.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf interactive session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T10:45:29.784313Z",
     "start_time": "2019-04-15T10:45:29.774738Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T10:45:29.872986Z",
     "start_time": "2019-04-15T10:45:29.864624Z"
    }
   },
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(gpu_options=gpu_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T10:45:34.946378Z",
     "start_time": "2019-04-15T10:45:31.021102Z"
    }
   },
   "outputs": [],
   "source": [
    "persistent_sess = tf.train.MonitoredSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T11:09:43.702848Z",
     "start_time": "2019-04-15T11:09:43.510454Z"
    }
   },
   "outputs": [],
   "source": [
    "persistent_sess = tf.train.MonitoredSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T11:10:07.786721Z",
     "start_time": "2019-04-15T11:10:04.633576Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2a6dffa79eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpersistent_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch26_inference_trt.pb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "persistent_sess.graph = load_graph('epoch26_inference_trt.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T10:45:34.946378Z",
     "start_time": "2019-04-15T10:45:31.021102Z"
    }
   },
   "outputs": [],
   "source": [
    "graph=load_graph('epoch26_inference_trt.pb'), config=sess_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-15T10:42:10.999Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_url = 0\n",
    "cap = cv2.VideoCapture(video_url)\n",
    "while True:\n",
    "    Disp.clear_output(wait=True)\n",
    "    ret,image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # process image\n",
    "    start = time.time()\n",
    "    op = persistent_sess.run(model_output,feed_dict={\n",
    "                        model_input: [image]})    \n",
    "    print(\"FPS = \",1/(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_useT():\n",
    "    with tf.Graph().as_default():\n",
    "        sentences = tf.placeholder(tf.string)\n",
    "        embed = hub.Module(module)\n",
    "        embeddings = embed(sentences)\n",
    "        session = tf.train.MonitoredSession()\n",
    "    return lambda x: session.run(embeddings, {sentences: x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normal graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T10:46:47.274995Z",
     "start_time": "2019-04-15T10:45:36.517873Z"
    }
   },
   "outputs": [],
   "source": [
    "video_url = '/home/prateek/Desktop/Video_Data/Video/5.In_front_of_engineering/Camera16_spandan office_spandan office_20181219102846_20181219102859_591291.mp4'\n",
    "video_url = 0\n",
    "trt_graph = get_graph('epoch26_inference_trt.pb')\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=.8)\n",
    "fps = []\n",
    "graph = tf.Graph()    \n",
    "cap = cv2.VideoCapture(0)\n",
    "with graph.as_default():\n",
    "    with tf.Session(config = tf.ConfigProto(gpu_options=gpu_options) ) as sess:\n",
    "        tf.import_graph_def(trt_graph, name='')\n",
    "        while True:\n",
    "            Disp.clear_output(wait=True)\n",
    "            ret,image = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            draw = image.copy()\n",
    "            draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # process image\n",
    "            start = time.time()\n",
    "            op = sess.run(model_output,feed_dict={\n",
    "                                model_input: [image]})    \n",
    "            print(\"FPS = \",1/(time.time()-start))\n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T10:46:56.464635Z",
     "start_time": "2019-04-15T10:46:56.461449Z"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T03:57:03.418031Z",
     "start_time": "2019-03-27T03:56:53.118768Z"
    }
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# with trt_detection_graph.as_default():\n",
    "    \n",
    "#     with tf.Session(graph=trt_detection_graph) as sess:\n",
    "#         while True:\n",
    "#             Disp.clear_output(wait=True)\n",
    "#             for i in range(1):\n",
    "#                 ret,image  = cap.read()\n",
    "#             draw = image.copy()\n",
    "#             draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#             # process image\n",
    "#             start = time.time()\n",
    "#             op = sess.run(model_output,feed_dict={\n",
    "#                                 model_input: [image]})\n",
    "\n",
    "#             #(boxes, scores, labels) = sess.run([boxes, scores,labels],feed_dict={image_tensor: image_np_expanded})\n",
    "#             print(\"FPS = \",1/(time.time()-start))\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-27T03:57:11.040819Z",
     "start_time": "2019-03-27T03:57:11.038102Z"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/f4f6da126e1bfc8e89b70161a82428b5"
  },
  "gist": {
   "data": {
    "description": "abg/helmet_n_vest/retinanet/tensorflow_model/tensorrt_retinanet_conversion.ipynb",
    "public": false
   },
   "id": "f4f6da126e1bfc8e89b70161a82428b5"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "cv_p35",
   "language": "python",
   "name": "cv_p35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
