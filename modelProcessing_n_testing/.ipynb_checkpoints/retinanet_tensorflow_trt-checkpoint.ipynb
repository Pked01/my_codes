{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess,sys\n",
    "from keras import backend as K\n",
    "from keras_retinanet import models\n",
    "import tensorflow as tf\n",
    "import cv2,os,datetime\n",
    "import numpy as np\n",
    "import time\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "import pandas as pd\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import IPython.display as Disp\n",
    "\n",
    "from keras_retinanet import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = datetime.datetime.now()\n",
    "file_name = t.strftime(\"%d_%m_%Y_%H_%M_%S_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### setting file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Get inference model\n",
    "model_name = \"resnet50_csv_28.h5\"\n",
    "retinanet_snapshot = \"../../../dataset/helmet_n_vest/snapshots/\"+model_name\n",
    "inference_model = \"../../../trained_models/helmet_n_vest/retinanet/inference_model/\"+file_name+os.path.basename(retinanet_snapshot)\n",
    "inference_model_tensorflow = \"../../../trained_models/helmet_n_vest/retinanet/inference_model/\"+file_name+os.path.basename(retinanet_snapshot).replace('h5','pb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snapshot_to_inference_retinanet(input_model_name,output_model_name,env='cv_p35'):\n",
    "    ! retinanet-convert-model {input_model_name} {output_model_name}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_snapshot_to_protobuf(input_model_name, output_model_name,save_graph_def=False):\n",
    "    !{sys.executable} keras_to_tensorflow.py --input_model={input_model_name}  --output_model={output_model_name} --save_graph_def={save_graph_def}\n",
    "#     subprocess.call(['python keras_to_tensorflow.py --input_model=\"../../retinanet/snapshots_1/resnet50_csv_19.h5\"  --output_model=\"model.pb\"'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(frozen_model_file):\n",
    "    \"\"\"\n",
    "    returns graphdef(unserialized) object\n",
    "    \"\"\"\n",
    "    with tf.gfile.GFile(frozen_model_file,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-05-07 09:39:44.252063: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-05-07 09:39:44.291165: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2019-05-07 09:39:44.291212: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: ip-172-31-20-69\n",
      "2019-05-07 09:39:44.291228: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: ip-172-31-20-69\n",
      "2019-05-07 09:39:44.291274: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 410.104.0\n",
      "2019-05-07 09:39:44.291311: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 410.104.0\n",
      "2019-05-07 09:39:44.291325: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 410.104.0\n",
      "2019-05-07 09:39:44.297282: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300020000 Hz\n",
      "2019-05-07 09:39:44.301715: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x43ad4e0 executing computations on platform Host. Devices:\n",
      "2019-05-07 09:39:44.301749: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "WARNING:tensorflow:From /home/ubuntu/Envs/cv_p35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "snapshot_to_inference_retinanet(retinanet_snapshot, inference_model)\n",
    "convert_snapshot_to_protobuf(inference_model, inference_model_tensorflow,save_graph_def=True)\n",
    "Disp.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating tensorrt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = 'input_1:0'\n",
    "model_output = ['filtered_detections/map/TensorArrayStack/TensorArrayGatherV3:0',\n",
    "               'filtered_detections/map/TensorArrayStack_1/TensorArrayGatherV3:0',\n",
    "               'filtered_detections/map/TensorArrayStack_2/TensorArrayGatherV3:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running against TensorRT version 5.0.2\n"
     ]
    }
   ],
   "source": [
    "precision = \"FP32\"\n",
    "batch_size=30\n",
    "workspace_size=1 << 25\n",
    "trt_graph = trt.create_inference_graph(get_graph(inference_model_tensorflow),model_output,\\\n",
    "                                       precision_mode=precision,max_workspace_size_bytes=workspace_size,\\\n",
    "                                      max_batch_size=batch_size,is_dynamic_op=True)\n",
    "\n",
    "with tf.gfile.GFile(inference_model_tensorflow.replace('inference_model','tensorrt_model').replace('.pb','_precision='+precision+'_batchsize='+str(batch_size)+'_trt.pb'),'wb') as f:\n",
    "    f.write(trt_graph.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_p35",
   "language": "python",
   "name": "cv_p35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
